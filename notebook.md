# QA
## Model Fitting
1. svm与神经网络相比
svm通过kernel匹配模型复杂度，很难做到匹配大数据集，可能几千几万个数据效果还可以。MLP通过激活函数可以做到大数据集下的拟合。svm可调性不强，kernel以及大小等。神经网络有点在于编程性强，以及end-to-end

2. 时序数据如何处理
比如一个月数据，不能离散的去划分。简单做法是将前三周数据作为训练集，最后一周数据作为验证

3. 参数与超参
模型参数指$w$和$b$，训练时需要学习的东西。超参数指的是线性模型、MLP、模型大小、学习率等

4. 如何有效设计超参数
随机组合，选取效果好的。手调。

5. 数据不平衡的情况下，数据集划分
有限数据集，至少valid中正负样本差不多。或者通过加权重来避免不平衡。

6. K折交叉验证的目的是确定超参吗，然后再用这个超参训练一遍全数据？
通过K折交叉验证确定超参，再重新训练
将K折中精度最高的模型最为最终模型
将K折中的K个模型都取下来，然后test在K个模型上进行预测，然后将最后结果取均值

## 参数初始化
1. nan和inf怎么产生和解决
inf：lr调太大，或者权重初始太大
nan：一个数除以0，通常梯度很小，除以0
合理的初始化权重，lr不要选太大。初始化权重的时候方差调小一点

2. sigmoid和relu
sigmoid容易引起梯度消失，但梯度消失不一定完全由sigmoid产生。relu可以很大程度上缓解梯度消失。

## 卷积神经网络
1. 感受野越大越好？
类似于MLP，做一个很浅，但是神经元特别大的。效果上来说不如网络做深，感受野小一点，最终目的一样。

2. loss抖动厉害
首先可能是因为数据分布差异大，可以做一个平滑。也有可能是学习率比较大。调学习率或者批量大小。
